# Blueprint - Gemini 3 Hackathon Submission

**One-Page Reference for Judges**

---

## ğŸ“± What is Blueprint?

An AI-powered language learning platform that transforms any content (articles, videos, audio) into interactive lessons using Google's Gemini 3 multimodal AI.

**Problem**: Traditional language tools give generic dictionary definitions without context.
**Solution**: Instant, contextual analysis of real-world content with grammar breakdowns, cultural notes, and personalized exercises.

**Live Demo**: https://blueprint-pearl.vercel.app/

---

## ğŸ¯ Gemini 3 Features Used (Central to Application)

### 1. â­ Native Structured Output
- **What**: Gemini returns perfectly structured JSON matching Pydantic schemas
- **Where**: `backend/services/gemini.py:56-63`
- **Why Central**: Every analysis (10+ types) uses structured output. Eliminates parsing errors and ensures data consistency across 20-50 API calls per user session.

```python
response = client.models.generate_content(
    model="gemini-3-flash-preview",
    contents=prompt,
    config=types.GenerateContentConfig(
        response_mime_type="application/json",
        response_schema=schemas.AnalysisResponse  # Pydantic model
    ),
)
result = response.parsed.model_dump()  # Already parsed!
```

### 2. ğŸš€ Extended Context Window (2M tokens)
- **What**: Analyze entire books/articles in one request
- **Where**: `backend/services/gemini.py:199-250`
- **Why Central**: Users import 10,000+ word articles. Gemini extracts top 50 vocabulary words ranked by usefulness, 15 grammar patterns, and maps difficulty progression across the full text. Chunking would lose context.

### 3. ğŸ¥ Multimodal (Vision + Audio)
- **What**: Process video + audio + text simultaneously
- **Where**: `backend/services/video_processor.py`
- **Why Central**: Users upload videos for learning. Gemini extracts timestamped subtitles, identifies vocabulary with context, and generates exercises - all from one API call. No external transcription service needed.

```python
with open(video_path, "rb") as video_file:
    video_part = types.Part.from_bytes(
        data=video_file.read(), mime_type="video/mp4"
    )
response = client.models.generate_content(
    model=GEMINI_MODELS["vision"],
    contents=[prompt, video_part],
)
```

---

## ğŸ—ï¸ Architecture

```
React/TypeScript Frontend
    â†“ (REST API)
FastAPI Backend
    â”œâ”€ GeminiService (text/audio analysis)
    â”œâ”€ VideoProcessor (multimodal analysis)
    â””â”€ CardService (flashcard generation)
    â†“ (API calls with structured schemas)
Gemini 3 API
    â”œâ”€ Flash (fast analysis, chat)
    â”œâ”€ Pro (complex reasoning)
    â””â”€ Vision (video/audio)
    â†“ (structured JSON responses)
SQLite Database (vocabulary, flashcards, progress)
```

**Tech Stack**: React 19, FastAPI, SQLAlchemy, Pydantic, Google GenAI SDK

---

## ğŸ¬ Key Demo Moments

1. **Text Analysis**: Click any word â†’ instant grammar breakdown, translation, usage examples (0.5s response)
2. **Video Learning**: Upload video â†’ timestamped subtitles â†’ clickable vocabulary that jumps to exact moment in video
3. **Long Content**: Import book chapter â†’ Gemini analyzes entire text â†’ extracts ranked vocabulary list

---

## ğŸ“Š Gemini 3 Usage Stats

| Feature | Gemini Model | API Calls | Response Format |
|---------|--------------|-----------|-----------------|
| Word Analysis | Flash | Per click (~20/session) | Structured JSON |
| Long Content | Pro | Per import | Structured JSON |
| Video Analysis | Vision | Per upload | Structured JSON |
| Audio Feedback | Audio | Per voice message | Structured JSON |
| Chat Practice | Flash | Per message | Structured JSON |
| Exercise Gen | Pro | On demand | Structured JSON |

**Total API calls per user session**: 20-50+
**All responses**: Native Structured Output with Pydantic schemas

---

## ğŸ’¡ Why Gemini 3 is CENTRAL (Not Peripheral)

âœ… **Every feature flows through Gemini** - Reader, video learning, flashcards, exercises, chat
âœ… **Structured output enables type safety** - Pydantic models used for API validation AND Gemini responses
âœ… **Extended context enables comprehensive analysis** - Can't rank vocabulary without seeing full text
âœ… **Multimodal unlocks video learning** - Single API call for subtitles + vocab + grammar
âœ… **Not a chatbot wrapper** - Deep integration of Gemini's advanced features

---

## ğŸ“ Use Cases

- **Self-learners**: Read news articles with instant word lookup and context
- **Video learners**: Watch YouTube videos with AI-generated subtitles and vocabulary extraction
- **Language enthusiasts**: Analyze entire books to find the most useful vocabulary before reading

**Supported Languages**: Spanish, French, German, Italian, Portuguese, Chinese, Japanese (+ any Gemini supports)

---

## ğŸ“ Documentation Provided

1. **DEMO_SCRIPT.md** - 3-minute presentation script with timestamps
2. **ARCHITECTURE.md** - Full system architecture with diagrams and data flows
3. **GEMINI_FEATURES_SUMMARY.md** - Detailed breakdown of all Gemini features used
4. **HACKATHON_PRESENTATION.md** - Complete presentation guide with Q&A prep
5. **This file** - Quick reference handout

---

## ğŸ”— Links

- **Live App**: https://blueprint-pearl.vercel.app/
- **Code**: Available on request (private repo during judging)
- **Video Demo**: [Link if you record one]

---

## ğŸ¤ Elevator Pitch (30 seconds)

"Blueprint is an AI-powered language learning platform that turns any content into an interactive lesson. Click any word in an article, and Gemini 3's **Native Structured Output** gives you instant grammar analysis. Upload a video, and Gemini's **multimodal capabilities** extract timestamped subtitles and vocabulary. Import a book chapter, and Gemini's **extended context window** analyzes the entire text to rank the most useful vocabulary.

We're not just using Gemini 3 as a chatbot - we're leveraging its advanced features to solve a real problem: making language learning contextual, interactive, and multimodal."

---

## âœ¨ Unique Technical Achievements

1. **Pydantic schemas as single source of truth** - Used for both API validation and Gemini response schemas
2. **Zero parsing errors** - Native Structured Output guarantees valid JSON
3. **True multimodal analysis** - Video + audio + text in one API call (not sequential processing)
4. **Type safety from API to UI** - Pydantic â†’ TypeScript interfaces match exactly
5. **Scalable architecture** - Service layer pattern, async/await, connection pooling

---

## ğŸ¯ Judging Criteria Coverage

âœ… **Problem Clarity**: Traditional tools lack context; Blueprint provides instant analysis
âœ… **Solution Effectiveness**: Live demo shows fast, accurate analysis of text and video
âœ… **Gemini 3 Integration**: Three primary features used deeply (structured output, extended context, multimodal)
âœ… **Technical Competence**: Clean architecture, type safety, well-documented code
âœ… **Demo Quality**: Smooth live demo with impressive video learning feature
âœ… **Documentation**: Four comprehensive docs + inline code comments

---

## ğŸš€ Future Roadmap

- Mobile apps (iOS/Android) with offline flashcard support
- Browser extension for instant word lookup on any webpage
- Gemini Live API integration for real-time conversation practice
- Community content sharing with annotations
- OCR for photos of menus/signs/books

---

## ğŸ‘¥ Team Contact

[Your Name]
[Your Email]
[GitHub/LinkedIn]

---

**Thank you for reviewing Blueprint!** We're excited to showcase what Gemini 3 can do when its advanced features are used thoughtfully in a real-world application.
