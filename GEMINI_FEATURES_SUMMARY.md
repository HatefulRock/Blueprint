# Gemini 3 Features Used in Blueprint

## Quick Reference for Hackathon Judges

---

## üéØ PRIMARY FEATURES (Core to Application)

### 1. ‚≠ê Native Structured Output
**What it is**: Gemini 3 returns perfectly structured JSON matching your Pydantic schemas instead of raw text.

**Where it's used**:
- `backend/services/gemini.py:56-63` - Word/sentence analysis
- `backend/services/gemini.py:228-235` - Long content analysis
- `backend/services/gemini.py:136-147` - Audio tutor feedback
- `backend/services/video_processor.py:107-111` - Video analysis

**Code Example**:
```python
response = client.models.generate_content(
    model="gemini-3-flash-preview",
    contents=prompt,
    config=types.GenerateContentConfig(
        response_mime_type="application/json",
        response_schema=schemas.AnalysisResponse  # Pydantic model
    ),
)
result = response.parsed.model_dump()  # Already parsed!
```

**Why it's central**:
- Every single feature in Blueprint relies on structured responses
- Eliminates parsing errors and ensures data consistency
- 10+ different schemas for different analysis types
- Without this, the entire app would need fragile regex parsing

**Schemas Used** (`backend/schemas.py`):
- `AnalysisResponse` (lines 430-443)
- `LongContentAnalysisResponse` (lines 524-532)
- `AudioTutorResponse` (lines 460-463)
- `ChatResponse` (lines 242-248)
- `QuizResponse` (lines 456-457)

---

### 2. üöÄ Extended Context Window (2M tokens)
**What it is**: Gemini 3 can process extremely long documents in a single request.

**Where it's used**:
- `backend/services/gemini.py:199-250` - `analyze_long_content()` method

**Code Example**:
```python
async def analyze_long_content(text: str, target_language: str) -> dict:
    """Use Gemini's extended context window to analyze entire books."""

    prompt = f"""
    Perform a COMPREHENSIVE analysis of this entire {target_language} text.
    Text Length: {len(text)} characters.

    Extract the 50 most valuable words ranked by usefulness (A1-C2).
    Identify 15 distinct grammar structures.
    Map difficulty progression (beginning/middle/end).
    """

    response = client.models.generate_content(
        model=GEMINI_MODELS["reasoning"],
        contents=[prompt, text],  # Entire book chapter in one call
        config=types.GenerateContentConfig(
            response_mime_type="application/json",
            response_schema=schemas.LongContentAnalysisResponse
        ),
    )
```

**Why it's central**:
- Users can import entire articles, book chapters, research papers
- Gemini analyzes the FULL context to rank vocabulary by usefulness
- Identifies progression of difficulty through the text
- Without this, would need to chunk text and lose context

**Real-world usage**:
- 10,000+ word articles analyzed in one request
- Novel chapters processed for comprehensive vocabulary extraction
- Academic papers broken down with key concepts

---

### 3. üé• Multimodal (Vision + Audio)
**What it is**: Gemini 3 can analyze video files (visual + audio + text) simultaneously.

**Where it's used**:
- `backend/services/video_processor.py` (entire file)
- `backend/routers/video.py` - Video upload endpoints
- `frontend/src/components/VideoLearningView.tsx` - UI for video learning

**Code Example**:
```python
async def analyze_video(self, video_path: str, target_language: str) -> Dict:
    """Use Gemini 3 Vision to analyze video content comprehensively."""

    with open(video_path, "rb") as video_file:
        video_part = types.Part.from_bytes(
            data=video_file.read(),
            mime_type="video/mp4"
        )

    prompt = f"""Analyze this {target_language} video comprehensively:

    1. TRANSCRIPTION: Generate accurate subtitles with timestamps
    2. VOCABULARY: Extract 20-30 key words/phrases
    3. GRAMMAR: Identify 5-10 grammar patterns
    4. DIFFICULTY: Estimate CEFR level
    5. CULTURAL CONTEXT: Note idioms and regional expressions
    """

    response = self.client.models.generate_content(
        model=GEMINI_MODELS["vision"],  # gemini-3-flash-preview
        contents=[prompt, video_part],
        config=types.GenerateContentConfig(
            response_mime_type="application/json"
        ),
    )
```

**Why it's central**:
- Users can learn from real-world videos (news, movies, vlogs)
- Synchronized subtitles with clickable vocabulary
- Timestamp-based navigation (click word ‚Üí jump to that moment)
- Visual context enhances comprehension
- No external transcription service needed

**What Gemini extracts**:
- Timestamped transcript (00:00 format)
- Vocabulary with context sentences and timestamps
- Grammar patterns demonstrated in the video
- Difficulty level (A1-C2)
- Cultural notes and idioms
- Auto-generated exercises

---

## üí° SUPPORTING FEATURES (Enhance Experience)

### 4. üé§ Audio Processing
**What it is**: Gemini transcribes audio and provides pronunciation feedback.

**Where it's used**:
- `backend/services/gemini.py:104-150` - `process_audio_tutor()` method

**Code Example**:
```python
def process_audio_tutor(audio_file_path: str, target_language: str):
    """Accepts audio and returns transcription, reply, and feedback."""

    with open(audio_file_path, "rb") as f:
        audio_content = f.read()

    response = client.models.generate_content(
        model=GEMINI_MODELS["audio"],
        contents=[
            prompt_text,
            types.Part.from_bytes(data=audio_content, mime_type="audio/mp3")
        ],
        config=types.GenerateContentConfig(
            response_mime_type="application/json",
            response_schema=schemas.AudioTutorResponse
        ),
    )
```

**What it provides**:
- Transcription of user's speech
- Pronunciation feedback with phonetic hints
- Grammar corrections with explanations
- Natural reply to continue conversation

---

### 5. üí¨ Live Chat API
**What it is**: Stateful conversations with maintained history.

**Where it's used**:
- `backend/services/gemini.py:168-197` - `get_chat_response()` method
- `frontend/src/components/ConversationView.tsx` - Chat interface

**Code Example**:
```python
def get_chat_response(user_text: str, history: list, target_language: str):
    """Stateful conversation with grammar feedback."""

    chat = client.chats.create(
        model=GEMINI_MODELS["default"],
        history=history  # Maintains conversation context
    )

    response = chat.send_message(
        message=prompt,
        config=types.GenerateContentConfig(
            response_mime_type="application/json",
            response_schema=schemas.ChatResponse
        ),
    )
```

**Use cases**:
- Conversation practice scenarios (restaurant, airport, shopping)
- Grammar correction with explanations
- Vocabulary reinforcement in dialogue

---

## üèóÔ∏è ARCHITECTURAL INTEGRATION

### Model Selection (`backend/config/gemini_models.py`)

```python
GEMINI_MODELS = {
    "default": "gemini-3-flash-preview",      # Fast analysis, chat
    "reasoning": "gemini-3-flash-preview",    # Long content, exercises
    "audio": "gemini-3-flash-preview",        # Audio transcription
    "vision": "gemini-3-flash-preview",       # Video/image analysis
    "tts": "gemini-3-flash-preview",          # Text-to-speech
    "live": "gemini-3-flash-preview",         # Real-time chat
}
```

### Centralized Service Pattern

All Gemini calls go through service classes:
- `GeminiService` - Text, audio, chat analysis
- `VideoProcessor` - Video/multimodal analysis
- `CardService` - Flashcard generation (uses Gemini analysis)

**Benefits**:
- Easy to test
- Centralized error handling
- Consistent schema usage
- Single source of truth for models

---

## üìä Usage Statistics Across Blueprint

| Feature | API Calls | Response Format | Latency |
|---------|-----------|-----------------|---------|
| Word Analysis | Every word click | Structured JSON | ~500ms |
| Long Content Analysis | Per article import | Structured JSON | ~3-5s |
| Video Analysis | Per video upload | Structured JSON | ~10-20s |
| Audio Tutor | Per voice message | Structured JSON | ~1-2s |
| Chat Response | Per message | Structured JSON | ~500ms |
| Exercise Generation | On demand | Structured JSON | ~2-3s |

**Total Gemini API calls per user session**: 20-50+
**All responses**: Structured JSON via Native Structured Output

---

## üéØ Why Gemini 3 is CENTRAL to Blueprint

1. **Native Structured Output eliminates fragility**
   - Without it: Need regex parsing, error-prone text extraction
   - With it: Guaranteed consistent data structure

2. **Extended Context enables comprehensive analysis**
   - Without it: Must chunk text, lose context, can't rank vocabulary globally
   - With it: Analyze entire books, understand full narrative arc

3. **Multimodal unlocks video learning**
   - Without it: Need separate transcription service + manual vocabulary extraction
   - With it: Single API call extracts subtitles + vocab + grammar + context

4. **Structured schemas create type safety**
   - Pydantic models used for both API validation AND Gemini responses
   - Frontend TypeScript interfaces match backend schemas
   - Zero drift between layers

5. **Every feature flows through Gemini**
   - Reader view: Word analysis via Gemini
   - Video learning: Multimodal analysis via Gemini
   - Flashcards: Generated from Gemini-analyzed vocabulary
   - Exercises: Created by Gemini reasoning model
   - Conversations: Powered by Gemini chat
   - Pronunciation: Feedback from Gemini audio model

---

## üìù Documentation Files

For judges, we've provided:
1. **DEMO_SCRIPT.md** - 3-minute presentation script with timestamps
2. **ARCHITECTURE.md** - Full system architecture with diagrams
3. **This file** - Quick reference of Gemini features used
4. **Code comments** - Extensive inline documentation in all service files

---

## üöÄ Try It Yourself

**Live Demo**: https://blueprint-pearl.vercel.app/

**Test Account** (if needed):
- Username: demo
- Password: demo123

**Sample Flows**:
1. Click "Library" ‚Üí Select a Spanish article ‚Üí Click any word
2. Upload a video (MP4, max 50MB) ‚Üí See multimodal analysis
3. Import an article URL ‚Üí See extended context analysis

---

## üí™ Gemini 3 Competitive Advantages Used

1. **Structured Output**: Not available in GPT-4 without complex function calling
2. **Extended Context**: Longer than most competitors (2M tokens)
3. **True Multimodal**: Processes video + audio + text simultaneously (not sequential)
4. **JSON Mode**: Guaranteed valid JSON without "maybe it's text, maybe it's JSON" issues
5. **Native SDK**: Clean Python API, not hacky REST wrappers

Blueprint is a showcase of Gemini 3's most powerful features applied to a real-world use case: making language learning interactive, contextual, and multimodal.
